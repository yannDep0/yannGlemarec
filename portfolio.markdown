---
layout: page
title: "Portfolio"
permalink: /portfolio/
---

<img src="{{ '/pictures/Diag_FridgeMovements.png' | relative_url }}" alt="User Study figure depicting the vibrotactile feedback propagation." width="500" style="display: block; margin: 0 auto; margin-top: 15px;" />

## ðŸ“° Modeling Effort Perception in virtual reality: A Parameter-Based Haptic Feedback Approach

This project is still under review. (Submission date 13 of November 2024)

---

<img src="{{ '/pictures/RealBoothHorizontalVirtual.jpg' | relative_url }}" alt="On the left the real study environment and on the right the virtual one which copy the real one." width="500" style="display: block; margin: 0 auto; margin-top: 15px;" />

## ðŸ“„ Towards Virtual Audience Simulation For Speech Therapy

HCI Group, University of WÃ¼rzburg (Germany) & Lab-STICC, ENIB (France) | 2022 | [DOI](https://doi.org/10.1145/3570945.3607348) 
Yann GlÃ©marec, Jean-Luc Lugrin, Amelie HÃ¶rman, CÃ©dric Buche, Norina Lauer, Marc Erich Latoschik |  | 

### Details

This project was a proof of concept for using our virtual audience simulation system in virtual reality in exposure therapy. Thus, in collaboration with Prof. Norina Lauer and her student Amelie HÃ¶rman, we conducted a preliminary user study to evaluate its potential use at the LogopÃ¤die Plus Praxis. This study highlights the relevant features of exposure therapy and limitations that mainly lower the simulation believability according to patients. On the therapist side, we mainly evaluated the acceptability and usability of the system as well as the web browser application we developed to supervise the simulation, i.e., the web application that controls the therapeutic scenario.

### ðŸ“Ž Abstract 

Virtual reality (VR) technology has shown promise in various therapeutic applications, particularly in exposure therapy for reducing fear of certain objects or activities, e.g., fear of heights or negative evaluation of others in social situations. VR has been shown to yield positive outcomes in follow-up studies and provides a safe and ecological therapeutic environment for therapists and their patients. This paper presents a collaborative effort to develop a VR speech therapy system that simulates a virtual audience for users to practice their public speaking skills. We describe a novel web-based graphical user interface that enables therapists to manage the therapy session using a simple timeline. Lastly, we present the results from a qualitative study with therapists and teachers with functional dysphonia, highlighting the potential of such an application to support and augment the therapists' work and the remaining challenges regarding the design of natural interactions, agent behaviors, and scenario customization for patients.

--- 

<img src="{{ '/pictures/teaserFigure.jpeg' | relative_url }}" alt="The three point of view in the STAGE, teacher, student in VR, and student in AR." width="700" style="display: block; margin: 0 auto; margin-top: 15px;" />


## ðŸ“° Controlling the Stage: A High-Level Control System for Virtual Audiences in Virtual Reality

HCI Group, University of WÃ¼rzburg (Germany) & Lab-STICC, ENIB (France) | 2022 | [DOI](https://dx.doi.org/10.3389/frvir.2022.876433) 
Yann GlÃ©marec, Jean-Luc Lugrin, Anne-Gwenn Bosser, CÃ©dric Buche, Marc Erich Latoschik|  | 

### Details

This paper introduces a large project in which we designed an educative application to let students practice their oral exams during covid. It is composed of a virtual reality application that let students use their slides using Decker, a markdown slide tool developped in WÃ¼rzburg, and a supervisor decktop application to monitor the virtual audience behaviour which listen to the presentation and to the student's presentation as well. It also includes various features, such as automatic feedback to analyse the student's behaviour, a REST API to control the system from a simple web browser. This virtual audience's behaviours is based on a rule based model I design earlier during my thesis that provide non-verbal behaviours (posture, facial expression, head movement, gaze), phatic expressions (e.g., 'mmhmm' with a nod while listening) and interactions between agents and the users (e.g., proxemics, scripted events like a character coming late). 

### ðŸ“Ž Abstract 

This article presents a novel method for controlling a virtual audience system (VAS) in a Virtual Reality (VR) application called STAGE, which was initially designed for supervised public speaking training in university seminars dedicated to preparing and delivering scientific talks. We are interested in creating pedagogicalÂ narratives: narratives encompass affective phenomena, and rather than organizing events changing the course of a training scenario, pedagogical plans using our system focus on organizing the affects it arouses for the trainees. Efficiently controlling a virtual audience towards a specific training objective while evaluating the speakerâ€™s performance presents a challenge for a seminar instructor: the high level of cognitive and physical demands required to be able to control the virtual audience whilst evaluating the speakerâ€™s performance, adjusting and allowing it to react to the userâ€™s behaviors and interactions quickly. A critical limitation of a number of existing systems is that they rely on a Wizard of Oz approach, where the tutor drives the audience in reaction to the userâ€™s performance. We address this problem by integrating with a VAS a high-level control component for tutors, which allows for using predefined audience behavior rules, defining custom ones, as well as intervening during run-time for finer control of the unfolding of the pedagogical plan. At its core, this component offers a tool to program, select, modify, and monitor interactive training narratives using a high-level representation. The STAGE offers the following features: i) a high-level API to program pedagogical narratives focusing on a specific public speaking situation and training objectives, ii) an interactive visualization interface, iii) computation and visualization of user metrics, iv) a semi-autonomous virtual audience composed of virtual spectators with automatic reactions to the speaker and surrounding spectators while following the pedagogical plan V) and the possibility for the instructor to embody a virtual spectator to ask questions or guide the speaker from within the Virtual Environment. We present here the design and implementation of the tutoring system and its integration in STAGE and discuss its reception by end-users.


--- 

<img src="{{ '/pictures/ScannedAvatar.jpg' | relative_url }}" alt="Three point of view of my scanned avatar in the STAGE application." width="700" style="display: block; margin: 0 auto; margin-top: 15px;" />

## ðŸ““ Thesis: Audience simulation and perception in virtual reality.

HCI Group, University of WÃ¼rzburg (Germany) & Lab-STICC, ENIB (France) | 2023 | [HAL](https://hal.science/tel-04182915v1) 

### ðŸ“Ž Abstract

Many training or exposure therapy applications simulate audiences in virtual reality (VR) to provide safe and ecological environments. However, audience simulation in VR presents many challenges related to creating attitudes from the agents' non-verbal behaviour. Furthermore, in VR, the animations and the realism of the characters, also called agents, can also create performance problems. The behaviour models used in these systems are not directly evaluated in VR and rely on online studies or the application domain experts' knowledge. Thus, the difference in technology and the subjectivity of user perception could influence evaluation results. Therefore, we propose an audience behaviour model evaluated in VR that generates the non-verbal behaviours of its members from a given attitude to improve the audiences' quality and facilitate their use in educational and therapeutic scenarios. We present a series of performance and user perception evaluations in VR aiming at validating the system's ability to simulate different types of attitudes (bored, interested, or critical) while preserving an optimal VR experience and providing a high-level control application facilitating seamless attitude change in real-time, notably for the creation of training scenarios. Finally, we validate the deployment feasibility of this model in training and exposure therapy applications used by professionals.

